---
title: 线性回归
author: ' curve'
date: '2018-04-06'
slug: ''
categories:
  - R
tags:
  - Linear regression
---



<p>作为统计学的支柱，线性回归有着不可替代的作用。同时线性模型同时还拥有着许多优点：</p>
<ol style="list-style-type: decimal">
<li>简单，并可以提供充分可解释的的描述</li>
<li>在面对缺少足够的数据的训练集、低信噪比、稀疏数据时线性模型比一些新奇的非线性模型要优秀。</li>
<li>对输入变量的变化，可扩大其使用范围。</li>
<li>许多非线性模式是线性模型的推广，线性模型是其他模型的基础。</li>
</ol>
<p>相比其他模型，线性模型似乎是一种简单的模型。但是想要了解透线性模型的方方面面绝非是一件容易的事情。</p>
<p>作为一个实用主义者，我们将通过 R 语言完成线性模型建模的一套流程，并在其中探讨一些细节。</p>
<p>首先，我们认为输入变量 <span class="math inline">\(X\)</span> 和输出变量 <span class="math inline">\(Y\)</span> 在现实生活中有着明确的线性关系。</p>
<p><span class="math display">\[
Y=f(X)+\epsilon
\]</span></p>
<p>其中 <span class="math inline">\(\epsilon\)</span> 为随机误差项，且均值为 0。这代表着，我们的模型是一个概率模型。其有着确定的部分（<span class="math inline">\(f(X)\)</span>）和不确定的部分（<span class="math inline">\(\epsilon\)</span>）。现实生活中自变量与因变量之间的关系往往是不确定的，因此我们需要用数据估计出：</p>
<p><span class="math display">\[
\hat{Y}=\hat{f}(X)
\]</span></p>
<p>对应线性模型即为：</p>
<p><span class="math display">\[
\hat { Y } = \hat { \beta } _ { 0} + \hat { \beta } _ { 1} X _ { 1 } + \dots + \hat { \beta } _ { k } X _ { k  } 
\]</span></p>
