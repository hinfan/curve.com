<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>curve</title>
    <link>/</link>
    <description>Recent content on curve</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 29 Apr 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Faster</title>
      <link>/2018/04/29/faster/</link>
      <pubDate>Sun, 29 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/29/faster/</guid>
      <description>得到同样结果的方式或许多种多样，但是简洁高效的方式或许要废些脑子。在 R 语言上追求更快，大致有三种方式：
避免循环，使用向量化计算 如果无法避免，通过 Rcpp 将代码编译成 C++ 多线程  假如你有这样一组数据:
head(data[2:4]) ## # A tibble: 6 x 3 ## 报告类型 分类 类别 ## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; ## 1 贷款,贷款,信用卡,信用卡,信用卡,信用卡,信用… 个人住房贷款,个人住房贷款,贷记卡,贷记卡,贷记卡,贷… 调动,调动,正常,正常,正常,正… ## 2 贷款,贷款,贷款,贷款,信用卡,信用卡,信用卡,… 个人住房贷款,个人消费贷款,个人消费贷款,个人经营性贷… 正常,正常,正常,正常,正常,正… ## 3 贷款,贷款,信用卡,贷款,贷款,贷款,贷款… 个人消费贷款,个人经营性贷款,贷记卡,其他,其他,其他… 正常,正常,正常,正常,正常,正… ## 4 贷款,贷款,贷款,信用卡,信用卡,信用卡,贷款… 个人经营性贷款,个人经营性贷款,个人经营性贷款,贷记卡… 正常,正常,正常,正常,正常,正… ## 5 贷款,信用卡,信用卡,信用卡 个人经营性贷款,贷记卡,贷记卡,贷记卡… 正常,正常,正常,正常… ## 6 贷款,信用卡,信用卡,信用卡,信用卡,信用卡,信… 个人经营性贷款,贷记卡,贷记卡,贷记卡,贷记卡,贷记卡… 正常,正常,正常,正常,正常,正… 数据框的每一行都折叠了若干条记录，不仅看起来让人觉得很不舒服，并且还无法向下进行分析。这里便需要将数据向下展开，每个格子放一个数据。无论如何我们都是要将数据拆开的：
system.time(unfold &amp;lt;- strsplit(data$报告类型, &amp;quot;,&amp;quot;)) ## user system elapsed ## 0.017 0.000 0.017 虽然 strsplit() 返回的是列表，但是通过 unlist() 我们可以得到数据的一列。</description>
    </item>
    
    <item>
      <title>讲不清楚的懂</title>
      <link>/2018/04/25/%E8%AE%B2%E4%B8%8D%E6%B8%85%E6%A5%9A%E7%9A%84%E6%87%82/</link>
      <pubDate>Wed, 25 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/25/%E8%AE%B2%E4%B8%8D%E6%B8%85%E6%A5%9A%E7%9A%84%E6%87%82/</guid>
      <description>ps：不知为何我想改标题，却不小心删除了内容，我试着复制吧&amp;hellip;
常常会面临：我懂，但是我给你讲不清楚&amp;hellip;
今日读了一篇名为 写教材 的博客。看完之后我开始思考，是否讲不清楚的懂是真的懂。
 最好的学习方式是教学；能教给别人是理解知识的最低门槛。换句话说，如果你做不到能给别人解释清楚一件事，那你可能并不理解这件事。
 从过去的经历看来，我可能并不是真的懂。
究其原因，似乎在大部分时间，我都倾向于用最小的脑力和最短的时间去完成一个新内容的学习。泛读，直切重点，用到的看，用不到的就忽略。这种“精致”的实用主义确实一定程度上节省了时间，但是后遗症同样不可避免。遗忘过快，重复工作的时候不得不再次查阅，可能会忽略必要的细节，无法向他人阐释清楚相关内容。
ps：年纪大可能，只复原了70%的内容&amp;hellip;</description>
    </item>
    
    <item>
      <title>如何制作一幅关系网图</title>
      <link>/2018/04/24/%E5%A6%82%E4%BD%95%E5%88%B6%E4%BD%9C%E4%B8%80%E5%B9%85%E5%85%B3%E7%B3%BB%E7%BD%91%E5%9B%BE/</link>
      <pubDate>Tue, 24 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/24/%E5%A6%82%E4%BD%95%E5%88%B6%E4%BD%9C%E4%B8%80%E5%B9%85%E5%85%B3%E7%B3%BB%E7%BD%91%E5%9B%BE/</guid>
      <description>近日简单看了下 Text Mining with R。其中第四章中讲到了如何在文本分析中进行词间关系分析。
library(ggraph) set.seed(2017) ggraph(bigram_graph, layout = &amp;quot;fr&amp;quot;) + geom_edge_link() + geom_node_point() + geom_node_text(aes(label = name), vjust = 1, hjust = 1) + theme_bw() 便联想到我的一组数据：
head(df[c(1,5)]) ## # A tibble: 6 x 2 ## 矿山名称 开采矿种 ## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; ## 1 紫金矿业集团股份有限公司紫金山金铜矿 金 ## 2 昆明安信达科技有限公司河口县芹菜塘铅锌矿 多金属 ## 3 西藏巨龙铜业有限公司驱龙铜多金属矿 铜 ## 4 江西铜业股份有限公司德兴铜矿 铜 ## 5 内蒙古自治区新巴尔虎右旗乌努格吐山铜钼矿 多金属 ## 6 锡林郭勒盟金仓矿业有限责任公司迪彦钦阿木铅锌银钼矿 钼 金属伴生是一种常见的现象。比如，从矿山命名中包含着“金—铜矿”，“铅-锌矿”，“铅-锌-银-钼矿”等等说明。不同的金属之间也有着不同的伴生关系，我们该如何呈现出这种关系呢？关系网图是一个很好的选择。
经过一番复杂的处理我们提取到了关键词：
head(kw) ## index chara len ## 1 2 铅锌 2 ## 2 5 铜钼 2 ## 3 6 铅锌银钼 4 ## 4 12 镍铜 2 ## 5 19 铜钼 2 ## 6 29 钼铜 2 因为探讨的是二元关系，则对应的数据格式应该是：</description>
    </item>
    
    <item>
      <title>plot 和 ggplot2</title>
      <link>/2018/04/22/plot-ggplot2/</link>
      <pubDate>Sun, 22 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/22/plot-ggplot2/</guid>
      <description>说起来也是奇怪，曾经觉得 ggplot2 要比 R 传统的 plot 要好看的多。但是最近突然发现 R 传统的画图搭配上合适的配色反而更好看。
想起曾经那段苦学 ggplot2 的日子也是苦不堪言的。各种 geom, stat, scale_等函数，真的是让人眼花缭乱。虽说理解了 ggplot2 背后的逻辑后，便会轻松不少。但是中文显示问题，主题的调节上，还是会让人觉得很繁琐。
好在如今也总算能用 ggplot2 做出各种各样的图，对细节的控制也越加游刃有余了。同时问题也暴露出来了。当时选择了 ggplot2 便放弃了 R 传统作图的学习。虽然避免了捡了芝麻丢了西瓜的尴尬，但是追求“新欢”的成本必然不会小。
 得不到的永远在骚动 被偏爱的都有恃无恐
 </description>
    </item>
    
    <item>
      <title>出院</title>
      <link>/2018/04/21/%E5%87%BA%E9%99%A2/</link>
      <pubDate>Sat, 21 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/21/%E5%87%BA%E9%99%A2/</guid>
      <description>仔细思索了一下，这确确实实是我第一次住院，尽管连24个小时都没有呆够。但也确确实实在手术室呆了约半个小时，也在医院睡了一晚。
周四的时候，医院给我打来了电话通知我周五过来做手术吧。距离第一次医生建议我做手术已经过去了差不多一个半月。
大概是在去年 11 月份左右的的时候觉得左眼睛有着明显的不适。当时觉得可能是用眼过度了，觉得休息休息就好了，期间断断续续，一直忍到今年 3 月。就诊后，医生说我是因为倒睫 导致眼角膜受损，建议做手术。</description>
    </item>
    
    <item>
      <title>Forcats 和 stringsAsFactors</title>
      <link>/2018/04/17/forcats-stringsasfactors/</link>
      <pubDate>Tue, 17 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/17/forcats-stringsasfactors/</guid>
      <description>今天来聊聊 forcats 包和 stringsAsFactors。
一切起因是在我给 map 添加图例的时候发现，分类变量(factor)有大概有快二十个。作为一个完美主义者，自然不能接受一长溜的图例，更重要的其中掺杂一些无足轻重的变量。这时我便想到了 forcats 包中的 fct_collapse() 函数，将其中一些变量折叠(collapse)成“其他”。
library(forcats) partyid2 &amp;lt;- fct_collapse(gss_cat$partyid, missing = c(&amp;quot;No answer&amp;quot;, &amp;quot;Don&amp;#39;t know&amp;quot;), other = &amp;quot;Other party&amp;quot;, rep = c(&amp;quot;Strong republican&amp;quot;, &amp;quot;Not str republican&amp;quot;), ind = c(&amp;quot;Ind,near rep&amp;quot;, &amp;quot;Independent&amp;quot;, &amp;quot;Ind,near dem&amp;quot;), dem = c(&amp;quot;Not str democrat&amp;quot;, &amp;quot;Strong democrat&amp;quot;) ) 看了眼示例，脑补了一下
fct_collapse(factor, A = A, B = B, ... , other = c(K, L, ...) ) 放弃了。坚持不懈的我发现了 frc_lump(). tips：lump(使成块状)。
x &amp;lt;- factor(rep(LETTERS[1:9], times = c(40, 10, 5, 27, 1, 1, 1, 1, 1))) x %&amp;gt;% table() ## .</description>
    </item>
    
    <item>
      <title>AWS</title>
      <link>/2018/04/15/aws/</link>
      <pubDate>Sun, 15 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/15/aws/</guid>
      <description>AWS &amp;amp; Shiny-server 从第一次见到 Shiny 到现在，Shiny 都一直都深深地吸引着我。你不必懂 JavaScript、CSS 和 HTML 就可生成可交互的 APP。
但是 Shiny 学习起来并不轻松，同时将 Shiny app 部署到网络上， 并分享给朋友也并不是一件容易的事情。虽然 Rstudio 贴心的提供了 shinyapps.io，配合上 Rstudio 可以轻松部署到 web 上。但是免费套餐的诸多限制，和以美元结算的套餐似乎都不是完美是选择。 好在AWS有免费的 EC-2 可以部署服务器，配置 Shiny-server。
但是作为一个非计算机专业的学生，面对着通过的 ssh 连接到 Ubuntu 虚拟机的命令行，让习惯了用 GUI 的系统的我着实一脸懵逼。经过了一番捣鼓，最后还是通过 Louis Aslett 友人提供的 RStudio Server Amazon Machine Image，避免了在完全不熟悉的 Ubuntu 上配置 R、Rstudio-server 和 shiny—server 的麻烦。事实上最初就是卡在这里了。
现在，我们可以通过 web 在浏览器上端访问 Rstudio 愉快地制作 shiny app 了。
附上半年前做的一个关于自改革开放以来的各省人均 GDP 的 APP。</description>
    </item>
    
    <item>
      <title>AIC, Cp and estimators of loss for elliptically symmetric distributions</title>
      <link>/2018/04/14/aic-cp-and-estimators-of-loss-for-elliptically-symmetric-distributions/</link>
      <pubDate>Sat, 14 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/14/aic-cp-and-estimators-of-loss-for-elliptically-symmetric-distributions/</guid>
      <description>这个是在查找 $C_p$ 统计量时，无意看到的一篇论文。虽然英文很渣，但是还是获益匪浅（未完&amp;hellip;）
AIC, Cp and estimators of loss for elliptically symmetric distributions Introduction 介绍 The problem of model selection has generated a lot of interest for many decades now and especially recently with the increased size of datasets. In such a context, it is important to model the observed data in a way that accounts for the sparsity of the parameter space. The principle of parsimony helps to avoid classical issues such as overfitting or computational error.</description>
    </item>
    
    <item>
      <title>MapReduce？</title>
      <link>/2018/04/10/mapreduce/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/10/mapreduce/</guid>
      <description>一直以来都很好奇 MapReduce 到底是个啥。自己也查阅了一些资料，并未成功的将这个抽象的概念转化为具体的事物。直到前几天帮朋友处理数据的时候，顿时茅塞顿开。原本也并不是什么很困难的事情，只不过友人的电脑可能有些陈旧，读取并合并28个各百万行的数据有些吃力。
想来最近学习了 purrr 包，正好可以一展拳脚。
library(data.table) library(purrr) ## 获取所有 csv 文件(并不严谨哦) csvs &amp;lt;- grep(&amp;quot;.csv&amp;quot;, list.files(), value = TRUE) data &amp;lt;- map(csvs, fread) %&amp;gt;% reduce(rbind)  (28个csv，用 map，fread 读取大概要 27s。reduce(., rbind) 部分要18秒左右。最后得到一个不到3000W行的dataframe。如果你看过我朋友，一个一个 data_i &amp;lt;- read.csv(&amp;hellip;) 的话，你会发现上面的方式是多么的简洁高效。)
map？reduce？MapReduce？似乎在那一刻我明白了点什么。</description>
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Thu, 05 Apr 2018 21:48:51 -0700</pubDate>
      
      <guid>/about/</guid>
      <description>关于？关于？等我想好了再填吧</description>
    </item>
    
    <item>
      <title>线性回归</title>
      <link>/2018/04/06/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Fri, 06 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/06/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</guid>
      <description>(未完成！)
简述 作为统计学的支柱，线性回归有着不可替代的作用。同时线性模型同时还拥有着许多优点：
简单，并可以提供充分可解释的的描述 在面对缺少足够的数据的训练集、低信噪比、稀疏数据时线性模型比一些新奇的非线性模型要优秀。 对输入变量的变化，可扩大其使用范围。 许多非线性模式是线性模型的推广，线性模型是其他模型的基础。  相比其他模型，线性模型似乎是一种简单的模型。但是想要了解透线性模型的方方面面绝非是一件容易的事情。
作为一个实用主义者，我们将通过 R 语言完成线性模型建模的一套流程，并在其中探讨一些细节。
首先，我们认为输入变量 \(X\) 和输出变量 \(Y\) 在现实生活中有着明确的线性关系。
\[ Y=f(X)+\epsilon \]
其中 \(\epsilon\) 为随机误差项，且均值为 0。这代表着，我们的模型是一个概率模型。其有着确定的部分（\(f(X)\)）和不确定的部分（\(\epsilon\)）。现实生活中自变量与因变量之间的关系往往是不确定的，因此我们需要用数据估计出：
\[ \hat{Y}=\hat{f}(X) \]
对应线性模型即为：
\[ \hat { Y } = \hat { \beta } _ { 0} + \hat { \beta } _ { 1} X _ { 1 } + \dots + \hat { \beta } _ { k } X _ { k } \]</description>
    </item>
    
    <item>
      <title>我的第一篇博客?</title>
      <link>/2018/04/05/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</link>
      <pubDate>Thu, 05 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/05/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</guid>
      <description>虽然并不知道要说些什么, 但不管怎么说第一篇博客终究还是要纪念一下的。
依稀记得学生时代被语文作文支配的恐惧。纠结来纠结去，最后草草了事。现在想想完美主义与生产力多半是冲突的。
以我对我的了解，三分钟热度的我不知道能坚持写几天博客，如果我坚持下来的话，那么就得好好思考思考是我变了，还是写博客有着神奇的魔力。
博客！写什么？随便啦。
如果日后我成为了作家，那我应该会被归类到意识流？
最后，虽然人是善变的，但是这么多年了，我依然想说：下雨天真的是好烦！</description>
    </item>
    
  </channel>
</rss>