<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on curve</title>
    <link>/post/</link>
    <description>Recent content in Posts on curve</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Apr 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>线性回归</title>
      <link>/2018/04/06/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Fri, 06 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/06/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</guid>
      <description>作为统计学的支柱，线性回归有着不可替代的作用。同时线性模型同时还拥有着许多优点：
简单，并可以提供充分可解释的的描述 在面对缺少足够的数据的训练集、低信噪比、稀疏数据时线性模型比一些新奇的非线性模型要优秀。 对输入变量的变化，可扩大其使用范围。 许多非线性模式是线性模型的推广，线性模型是其他模型的基础。  相比其他模型，线性模型似乎是一种简单的模型。但是想要了解透线性模型的方方面面绝非是一件容易的事情。
作为一个实用主义者，我们将通过 R 语言完成线性模型建模的一套流程，并在其中探讨一些细节。
首先，我们认为输入变量 \(X\) 和输出变量 \(Y\) 在现实生活中有着明确的线性关系。
\[ Y=f(X)+\epsilon \]
其中 \(\epsilon\) 为随机误差项，且均值为 0。这代表着，我们的模型是一个概率模型。其有着确定的部分（\(f(X)\)）和不确定的部分（\(\epsilon\)）。现实生活中自变量与因变量之间的关系往往是不确定的，因此我们需要用数据估计出：
\[ \hat{Y}=\hat{f}(X) \]
对应线性模型即为：
\[ \hat { Y } = \hat { \beta } _ { 0} + \hat { \beta } _ { 1} X _ { 1 } + \dots + \hat { \beta } _ { k } X _ { k } \]</description>
    </item>
    
    <item>
      <title>我的第一篇博客?</title>
      <link>/2018/04/05/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</link>
      <pubDate>Thu, 05 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/05/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</guid>
      <description>虽然并不知道要说些什么, 但不管怎么说第一篇博客终究还是要纪念一下的。
依稀记得学生时代被语文作文支配的恐惧。纠结来纠结去，最后草草了事。现在想想完美主义与生产力多半是冲突的。
以我对我的了解，三分钟热度的我不知道能坚持写几天博客，如果我坚持下来的话，那么就得好好思考思考是我变了，还是写博客有着神奇的魔力。
博客！写什么？随便啦。
如果日后我成为了作家，那我应该会被归类到意识流？
最后，虽然人是善变的，但是这么多年了，我依然想说：下雨天真的是好烦！</description>
    </item>
    
  </channel>
</rss>