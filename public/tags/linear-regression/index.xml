<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Linear Regression on curve</title>
    <link>/tags/linear-regression/</link>
    <description>Recent content in Linear Regression on curve</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Apr 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/linear-regression/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>线性回归</title>
      <link>/2018/04/06/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Fri, 06 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/06/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</guid>
      <description>(未完成！)
简述 作为统计学的支柱，线性回归有着不可替代的作用。同时线性模型同时还拥有着许多优点：
简单，并可以提供充分可解释的的描述 在面对缺少足够的数据的训练集、低信噪比、稀疏数据时线性模型比一些新奇的非线性模型要优秀。 对输入变量的变化，可扩大其使用范围。 许多非线性模式是线性模型的推广，线性模型是其他模型的基础。  相比其他模型，线性模型似乎是一种简单的模型。但是想要了解透线性模型的方方面面绝非是一件容易的事情。
作为一个实用主义者，我们将通过 R 语言完成线性模型建模的一套流程，并在其中探讨一些细节。
首先，我们认为输入变量 \(X\) 和输出变量 \(Y\) 在现实生活中有着明确的线性关系。
\[ Y=f(X)+\epsilon \]
其中 \(\epsilon\) 为随机误差项，且均值为 0。这代表着，我们的模型是一个概率模型。其有着确定的部分（\(f(X)\)）和不确定的部分（\(\epsilon\)）。现实生活中自变量与因变量之间的关系往往是不确定的，因此我们需要用数据估计出：
\[ \hat{Y}=\hat{f}(X) \]
对应线性模型即为：
\[ \hat { Y } = \hat { \beta } _ { 0} + \hat { \beta } _ { 1} X _ { 1 } + \dots + \hat { \beta } _ { k } X _ { k } \]</description>
    </item>
    
  </channel>
</rss>